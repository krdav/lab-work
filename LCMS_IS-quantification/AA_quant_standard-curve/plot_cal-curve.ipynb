{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, re, copy\n",
    "import dill as pickle # this serializes all the functions inside the quantification dict\n",
    "import numpy as np\n",
    "from scipy.optimize import newton, minimize, fsolve\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.backends.backend_pdf\n",
    "import matplotlib.colors as mcolors\n",
    "palette = list(mcolors.TABLEAU_COLORS.keys())\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\", {\n",
    " 'axes.spines.bottom': True,\n",
    " 'axes.spines.left': True,\n",
    " 'axes.spines.right': True,\n",
    " 'axes.spines.top': True\n",
    "})\n",
    "sns.set(font_scale=1)\n",
    "palette = list(mcolors.TABLEAU_COLORS.keys())\n",
    "sns.set_theme(style=\"ticks\", palette=\"muted\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit and plot calibration curve for amino acid quantification\n",
    "This program takes LCMS data from TraceFinder and generates calibration curves to quantify compounds using isotopically labelled internal standards. The input data is a dilution series of compounds with a constant concentration of isotopically internal standard associated for each compound. The peak area of each compound is normalized to its internal standard (this is the \"response ratio\") and a curve is fitted to this data. The curve fitting will choose the best curve among 1) linear fit, 2) power fit and 3) 2. degree polynomial fit. The chosen curve will be used for interpolation and two linear fits will be used for extrapolation; one below the lowest concentration in the calibration curve (forced to intersect 0) and one above the highest concentration in the calibration curve. The three curves are connected to a piecewise fit. The loss function used to chose and fit the curves are defined as the sum of the percentage deviation between true and predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_piece_wise_fit(amt_uM, rsp_ratio, amt_uM_range, rsp_ratio_range, df, debug=True):\n",
    "    '''\n",
    "    This function returns a piecewise function y = f(x)\n",
    "    x = response ratio\n",
    "    y = imputed sample concentration\n",
    "    '''\n",
    "    \n",
    "    ### Here comes all functions related to curve fitting ###\n",
    "    ### It is necessary to define these here so they get serialized during pickling ###\n",
    "    # Loss functions:\n",
    "    def loss_func_c1(t, y):\n",
    "        return((np.abs(y - t) / t) * 100)\n",
    "    def loss_func_l1(t, y):\n",
    "        return(np.abs(y - t))  # l1\n",
    "    def loss_func_l2(t, y):\n",
    "        return((y - t)**2)     # l2\n",
    "\n",
    "    # Linear fit intersecting 0:\n",
    "    def lin_fit(x, beta):\n",
    "        return(x*beta)\n",
    "    def obj_lin_fit(loss_func, amt_uM, rsp_ratio, p):\n",
    "        beta = p[0]\n",
    "        y = lin_fit(rsp_ratio, beta)\n",
    "        loss = sum(loss_func(amt_uM, y))\n",
    "        return(loss)\n",
    "    # Linear fit allowed to be offset 0:\n",
    "    def lin_fit_off(x, alpha, beta):\n",
    "        return(alpha + x*beta)\n",
    "    def obj_lin_fit_off(loss_func, amt_uM, rsp_ratio, p):\n",
    "        alpha = p[0]\n",
    "        beta = p[1]\n",
    "        y = lin_fit_off(rsp_ratio, alpha, beta)\n",
    "        loss = sum(loss_func(amt_uM, y))\n",
    "        return(loss)\n",
    "\n",
    "    # Second degree polynomial fit intersecting 0:\n",
    "    def pol2d_fit(x, beta, gamma):\n",
    "        return(x**2*beta + x*gamma)\n",
    "    def obj_pol2d_fit(loss_func, amt_uM, rsp_ratio, p):\n",
    "        beta = p[0]\n",
    "        gamma = p[1]\n",
    "        y = pol2d_fit(rsp_ratio, beta, gamma)\n",
    "        loss = sum(loss_func(amt_uM, y))\n",
    "        return(loss)\n",
    "    # Second degree polynomial fit allowed to be offset 0:\n",
    "    def pol2d_fit_off(x, alpha, beta, gamma):\n",
    "        return(alpha + x**2*beta + x*gamma)\n",
    "    def obj_pol2d_fit_off(loss_func, amt_uM, rsp_ratio, p):\n",
    "        alpha = p[0]\n",
    "        beta = p[1]\n",
    "        gamma = p[2]\n",
    "        y = pol2d_fit_off(rsp_ratio, alpha, beta, gamma)\n",
    "        loss = sum(loss_func(amt_uM, y))\n",
    "        return(loss)\n",
    "\n",
    "    # Power fit intersecting 0:\n",
    "    def pow_fit(x, beta, gamma):\n",
    "        return(beta*x**gamma)\n",
    "    def obj_pow_fit(loss_func, amt_uM, rsp_ratio, p):\n",
    "        beta = p[0]\n",
    "        gamma = p[1]\n",
    "        y = pow_fit(rsp_ratio, beta, gamma)\n",
    "        loss = sum(loss_func(amt_uM, y))\n",
    "        return(loss)\n",
    "    # Power fit allowed to be offset 0:\n",
    "    def pow_fit_off(x, alpha, beta, gamma):\n",
    "        return(alpha + beta*x**gamma)\n",
    "    def obj_pow_fit_off(loss_func, amt_uM, rsp_ratio, p):\n",
    "        alpha = p[0]\n",
    "        beta = p[1]\n",
    "        gamma = p[2]\n",
    "        y = pow_fit_off(rsp_ratio, alpha, beta, gamma)\n",
    "        loss = sum(loss_func(amt_uM, y))\n",
    "        return(loss)\n",
    "\n",
    "    # Functions to pick the best interpolation, intersecting 0:\n",
    "    def pick_best_fun(t, x):\n",
    "        bnds = ((0, None),)\n",
    "        def fun_lin(p): return(obj_lin_fit(loss_func_c1, t, x, p))\n",
    "        p_lin = minimize(fun_lin, (1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        bnds = ((None, None), (0, None))\n",
    "        def fun_pol2d(p): return(obj_pol2d_fit(loss_func_c1, t, x, p))\n",
    "        p_pol2d = minimize(fun_pol2d, (1, 1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        bnds = ((0, None), (0, None))\n",
    "        def fun_pow(p): return(obj_pow_fit(loss_func_c1, t, x, p))\n",
    "        p_pow = minimize(fun_pow, (0.4, 1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        loss_list = [p_lin.fun, p_pol2d.fun, p_pow.fun]\n",
    "        func_list = [lambda x: lin_fit(x, p_lin.x[0]), lambda x: pol2d_fit(x, p_pol2d.x[0], p_pol2d.x[1]), lambda x: pow_fit(x, p_pow.x[0], p_pow.x[1])]\n",
    "        min_idx = loss_list.index(min(loss_list))\n",
    "        best_fun = func_list[min_idx]\n",
    "        return(best_fun)\n",
    "    def pick_best_fun_l1(t, x):\n",
    "        bnds = ((0, None),)\n",
    "        def fun_lin(p): return(obj_lin_fit(loss_func_l1, t, x, p))\n",
    "        p_lin = minimize(fun_lin, (1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        bnds = ((None, None), (0, None))\n",
    "        def fun_pol2d(p): return(obj_pol2d_fit(loss_func_l1, t, x, p))\n",
    "        p_pol2d = minimize(fun_pol2d, (1, 1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        bnds = ((0, None), (0, None))\n",
    "        def fun_pow(p): return(obj_pow_fit(loss_func_l1, t, x, p))\n",
    "        p_pow = minimize(fun_pow, (0.4, 1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        loss_list = [p_lin.fun, p_pol2d.fun, p_pow.fun]\n",
    "        func_list = [lambda x: lin_fit(x, p_lin.x[0]), lambda x: pol2d_fit(x, p_pol2d.x[0], p_pol2d.x[1]), lambda x: pow_fit(x, p_pow.x[0], p_pow.x[1])]\n",
    "        min_idx = loss_list.index(min(loss_list))\n",
    "        best_fun = func_list[min_idx]\n",
    "        return(best_fun)\n",
    "    def pick_best_fun_l2(t, x):\n",
    "        bnds = ((0, None),)\n",
    "        def fun_lin(p): return(obj_lin_fit(loss_func_l2, t, x, p))\n",
    "        p_lin = minimize(fun_lin, (1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        bnds = ((None, None), (0, None))\n",
    "        def fun_pol2d(p): return(obj_pol2d_fit(loss_func_l2, t, x, p))\n",
    "        p_pol2d = minimize(fun_pol2d, (1, 1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        bnds = ((0, None), (0, None))\n",
    "        def fun_pow(p): return(obj_pow_fit(loss_func_l2, t, x, p))\n",
    "        p_pow = minimize(fun_pow, (0.4, 1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        loss_list = [p_lin.fun, p_pol2d.fun, p_pow.fun]\n",
    "        func_list = [lambda x: lin_fit(x, p_lin.x[0]), lambda x: pol2d_fit(x, p_pol2d.x[0], p_pol2d.x[1]), lambda x: pow_fit(x, p_pow.x[0], p_pow.x[1])]\n",
    "        min_idx = loss_list.index(min(loss_list))\n",
    "        best_fun = func_list[min_idx]\n",
    "        return(best_fun)\n",
    "\n",
    "    # Functions to pick the best interpolation allowed to be offset 0:\n",
    "    def pick_best_fun_off(t, x):\n",
    "        bnds = ((None, None), (0, None))\n",
    "        def fun_lin(p): return(obj_lin_fit_off(loss_func_c1, t, x, p))\n",
    "        p_lin1 = minimize(fun_lin, (0, 1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        bnds = ((None, None), (0, None))\n",
    "        def fun_lin(p): return(obj_lin_fit_off(loss_func_c1, t, x, p))\n",
    "        p_lin2 = minimize(fun_lin, (0, 1), method='SLSQP', bounds=bnds)\n",
    "\n",
    "        bnds = ((None, None), (None, None), (0, None))\n",
    "        def fun_pol2d(p): return(obj_pol2d_fit_off(loss_func_c1, t, x, p))\n",
    "        p_pol2d1 = minimize(fun_pol2d, (0, 1, 1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        bnds = ((None, None), (None, None), (0, None))\n",
    "        def fun_pol2d(p): return(obj_pol2d_fit_off(loss_func_c1, t, x, p))\n",
    "        p_pol2d2 = minimize(fun_pol2d, (0, 1, 1), method='SLSQP', bounds=bnds)\n",
    "\n",
    "        bnds = ((None, None), (0, None), (0, None))\n",
    "        def fun_pow(p): return(obj_pow_fit_off(loss_func_c1, t, x, p))\n",
    "        p_pow1 = minimize(fun_pow, (0, 0.4, 1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        bnds = ((None, None), (0, None), (0, None))\n",
    "        def fun_pow(p): return(obj_pow_fit_off(loss_func_c1, t, x, p))\n",
    "        p_pow2 = minimize(fun_pow, (0, 0.4, 1), method='SLSQP', bounds=bnds)\n",
    "\n",
    "        loss_list = [p_lin1.fun, p_lin2.fun, p_pol2d1.fun, p_pol2d2.fun, p_pow1.fun, p_pow2.fun]\n",
    "        func_list = [lambda x: lin_fit_off(x, p_lin1.x[0], p_lin1.x[1]), lambda x: lin_fit_off(x, p_lin2.x[0], p_lin2.x[1]), lambda x: pol2d_fit_off(x, p_pol2d1.x[0], p_pol2d1.x[1], p_pol2d1.x[2]), lambda x: pol2d_fit_off(x, p_pol2d2.x[0], p_pol2d2.x[1], p_pol2d2.x[2]), lambda x: pow_fit_off(x, p_pow1.x[0], p_pow1.x[1], p_pow1.x[2]), lambda x: pow_fit_off(x, p_pow2.x[0], p_pow2.x[1], p_pow2.x[2])]\n",
    "        min_idx = loss_list.index(min(loss_list))\n",
    "        best_fun = func_list[min_idx]\n",
    "        return(best_fun)\n",
    "    def pick_best_fun_off_l1(t, x):\n",
    "        bnds = ((None, None), (0, None))\n",
    "        def fun_lin(p): return(obj_lin_fit_off(loss_func_l1, t, x, p))\n",
    "        p_lin = minimize(fun_lin, (0, 1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        bnds = ((None, None), (None, None), (0, None))\n",
    "        def fun_pol2d(p): return(obj_pol2d_fit_off(loss_func_l1, t, x, p))\n",
    "        p_pol2d = minimize(fun_pol2d, (0, 1, 1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        bnds = ((None, None), (0, None), (0, None))\n",
    "        def fun_pow(p): return(obj_pow_fit_off(loss_func_l1, t, x, p))\n",
    "        p_pow = minimize(fun_pow, (0, 0.4, 1), method='L-BFGS-B', bounds=bnds)\n",
    "\n",
    "        loss_list = [p_lin.fun, p_pol2d.fun, p_pow.fun]\n",
    "        func_list = [lambda x: lin_fit_off(x, p_lin.x[0], p_lin.x[1]), lambda x: pol2d_fit_off(x, p_pol2d.x[0], p_pol2d.x[1], p_pol2d.x[2]), lambda x: pow_fit_off(x, p_pow.x[0], p_pow.x[1], p_pow.x[2])]\n",
    "        min_idx = loss_list.index(min(loss_list))\n",
    "        best_fun = func_list[min_idx]\n",
    "        return(best_fun)\n",
    "\n",
    "    # Function to pick the best extrapolation:\n",
    "    def pick_lin_fun(t, x, off):\n",
    "        if off is True:\n",
    "            bnds = ((None, None), (0, None))\n",
    "            def fun_lin(p): return(obj_lin_fit_off(loss_func_l1, t, x, p))\n",
    "            p_lin = minimize(fun_lin, (0, 1), method='L-BFGS-B', bounds=bnds)\n",
    "            return(lambda x: lin_fit_off(x, p_lin.x[0], p_lin.x[1]))\n",
    "        elif off is False:\n",
    "            bnds = ((0, None),)\n",
    "            def fun_lin(p): return(obj_lin_fit(loss_func_l1, t, x, p))\n",
    "            p_lin = minimize(fun_lin, (1), method='L-BFGS-B', bounds=bnds)\n",
    "            return(lambda x: lin_fit(x, p_lin.x[0]))\n",
    "        else:\n",
    "            raise Exception('Unrecognized off: {}'.format(off))\n",
    "\n",
    "\n",
    "    ### Now creating the quant function ###    \n",
    "    piece_wise_fit = dict()\n",
    "    smo_frac = 0.4 # linear smoothening, fraction +/- response ratio\n",
    "\n",
    "    ### Extrapolate above highest response ratio ###\n",
    "    ub = rsp_ratio_range[0]\n",
    "    lb = rsp_ratio_range[1] + smo_frac*rsp_ratio_range[1]\n",
    "    key_extra_up = (ub, lb)\n",
    "\n",
    "    mask = (amt_uM == amt_uM_range[1]) | (amt_uM == amt_uM_range[2]) | (amt_uM == amt_uM_range[3]) | (amt_uM == amt_uM_range[4]) | (amt_uM == amt_uM_range[5])\n",
    "    amt_uM_tmp = amt_uM[mask]\n",
    "    rsp_ratio_tmp = rsp_ratio[mask]\n",
    "\n",
    "    # Restrict the extrapolation to linear fit:\n",
    "    # piece_wise_fit[key_extra_up] = pick_best_fun(amt_uM_tmp, rsp_ratio_tmp)\n",
    "    piece_wise_fit[key_extra_up] = pick_lin_fun(amt_uM_tmp, rsp_ratio_tmp, True)\n",
    "\n",
    "    ### Interpolate between highest and lowest response ratio ###\n",
    "    ub = rsp_ratio_range[1] - smo_frac*rsp_ratio_range[1]\n",
    "    lb = rsp_ratio_range[len(amt_uM_range)-2] + smo_frac*rsp_ratio_range[len(amt_uM_range)-2]\n",
    "    key_intra = (ub, lb)\n",
    "    piece_wise_fit[key_intra] = pick_best_fun_off(amt_uM, rsp_ratio)\n",
    "\n",
    "    ### Smoothen between the upper extrapolation and the intrapolation ###\n",
    "    ub = rsp_ratio_range[1] + smo_frac*rsp_ratio_range[1]\n",
    "    lb = rsp_ratio_range[1] - smo_frac*rsp_ratio_range[1]\n",
    "    key_between_intra_up = (ub, lb)\n",
    "    \n",
    "    y_upper = piece_wise_fit[key_extra_up](ub)\n",
    "    y_lower = piece_wise_fit[key_intra](lb)\n",
    "\n",
    "    beta_upper = (y_upper - y_lower) / (ub - lb)\n",
    "    if beta_upper < 0:\n",
    "        print('Upper smoothening gave negative slope!!! Maybe adjust smo_frac.')\n",
    "    alpha_upper = y_upper - beta_upper*ub\n",
    "    piece_wise_fit[key_between_intra_up] = lambda x: alpha_upper + beta_upper*x\n",
    "\n",
    "    ### Extrapolate between 0 and lowest response ratio ###\n",
    "    ub = rsp_ratio_range[len(amt_uM_range)-2] - smo_frac*rsp_ratio_range[len(amt_uM_range)-2]\n",
    "    lb = rsp_ratio_range[len(amt_uM_range)-1]\n",
    "    key_extra_low = (ub, lb)\n",
    "\n",
    "    i = len(amt_uM_range)-2\n",
    "    # Extrapolate from the 5 lowest concentrations:\n",
    "    mask = (amt_uM == amt_uM_range[i-3]) | (amt_uM == amt_uM_range[i-2]) | (amt_uM == amt_uM_range[i-1]) | (amt_uM == amt_uM_range[i]) | (amt_uM == amt_uM_range[i+1])\n",
    "    amt_uM_tmp = amt_uM[mask]\n",
    "    rsp_ratio_tmp = rsp_ratio[mask]\n",
    "    piece_wise_fit[key_extra_low] = pick_best_fun_l1(amt_uM_tmp, rsp_ratio_tmp)\n",
    "    #piece_wise_fit[key_extra_low] = pick_lin_fun(amt_uM_tmp, rsp_ratio_tmp, False)\n",
    "\n",
    "    ### Smoothen between the lower extrapolation and the intrapolation ###\n",
    "    ub = rsp_ratio_range[len(amt_uM_range)-2] + smo_frac*rsp_ratio_range[len(amt_uM_range)-2]\n",
    "    lb = rsp_ratio_range[len(amt_uM_range)-2] - smo_frac*rsp_ratio_range[len(amt_uM_range)-2]\n",
    "    key_between_intra_low = (ub, lb)\n",
    "    \n",
    "    y_upper = piece_wise_fit[key_intra](ub)\n",
    "    y_lower = piece_wise_fit[key_extra_low](lb)\n",
    "\n",
    "    beta_lower = (y_upper - y_lower) / (ub - lb)\n",
    "    if beta_lower < 0:\n",
    "        print('Lower smoothening gave negative slope!!! Maybe adjust smo_frac.')\n",
    "    alpha_lower = y_upper - beta_lower*ub\n",
    "    piece_wise_fit[key_between_intra_low] = lambda x: alpha_lower + beta_lower*x\n",
    "\n",
    "    if debug is True:\n",
    "        plot_cal_curve(df, piece_wise_fit)\n",
    "\n",
    "    return(piece_wise_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_conc(piece_wise_fit_metab, response_ratio):\n",
    "    '''\n",
    "    This function imputes the concentration from a response ratio.\n",
    "    '''\n",
    "    response_ratio_range = np.array(list(piece_wise_fit_metab.keys()))\n",
    "    mask_range = [response_ratio >= min_v and response_ratio <= max_v for max_v, min_v in response_ratio_range]\n",
    "    k = tuple(response_ratio_range[mask_range][0])\n",
    "    return(piece_wise_fit_metab[k](response_ratio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cal_curve(df, piece_wise_fit_metab):\n",
    "    '''\n",
    "    Plot for debugging.\n",
    "    '''\n",
    "    plt.figure(figsize=(5, 4))\n",
    "    #plt.scatter(rr_mes_metab, imp_conc_mes_metab, color='red', marker='x')\n",
    "    ax = sns.scatterplot(x=\"Response Ratio\", y=\"Theoretical Amt\", data=df)\n",
    "    ax.set(xscale=\"log\", yscale=\"log\")\n",
    "    ax.set_title('{}'.format(metab))\n",
    "    for k in piece_wise_fit_metab.keys():\n",
    "        ub, lb = k\n",
    "        if ub == float('inf'):\n",
    "            ub = 3*lb\n",
    "        if lb == 0:\n",
    "            lb = ub * 1e-1\n",
    "        x = np.linspace(lb, ub, 1000)\n",
    "        y = piece_wise_fit_metab[k](x)\n",
    "        plt.plot(x, y, linewidth=1, color='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cal_piece_wise_fit(metab, df, piece_wise_fit_metab, save=False, linscale=False):\n",
    "    '''\n",
    "    Plot the calibration curve data with the piece wise fit.\n",
    "    '''\n",
    "    if linscale: # Plot measured points on linear scale\n",
    "        plt.figure(figsize=(7, 6))\n",
    "        ax = sns.scatterplot(rr_mes_metab, imp_conc_mes_metab, color='red', marker='x')\n",
    "        ax.set_title('Lin. mes. {}'.format(metab))\n",
    "        plt.show()\n",
    "    else: # Plot both measured and calibration points on log-log scale\n",
    "        fig, ax1 = plt.subplots(1, 1, figsize=(6, 5.4))\n",
    "\n",
    "        g1 = sns.scatterplot(ax=ax1, x=\"Response Ratio\", y=\"Theoretical Amt\", data=df)\n",
    "        g1.set(xscale=\"log\", yscale=\"log\", ylabel='Concentration (Î¼M)')\n",
    "        g1.set_title('{}'.format(metab[0:-4]))\n",
    "        g1.grid(True)\n",
    "\n",
    "        for line_idx, k in enumerate(piece_wise_fit_metab.keys()):\n",
    "            ub, lb = k\n",
    "            if ub == float('inf'): # Extrapolation (over)\n",
    "                ub = 3*lb\n",
    "            if lb == 0: # Extrapolation (under)\n",
    "                lb = ub * 0.5\n",
    "            x = np.logspace(np.log10(lb), np.log10(ub), 1000)\n",
    "            y = piece_wise_fit_metab[k](x)\n",
    "            ax1.plot(x, y, linewidth=1, color='black', linestyle='--')\n",
    "            # ax1.plot(x, y, linewidth=2, color=palette[line_idx], linestyle='--')\n",
    "\n",
    "        fig.tight_layout()\n",
    "        if save:\n",
    "            return(fig)\n",
    "        else:\n",
    "            fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-18-75bec30a55f8>:14: RuntimeWarning: invalid value encountered in true_divide\n",
      "  df_tmp['Response Ratio'] = df_tmp['Area'].values / df_tmp['ISTD Response'].values\n",
      "<ipython-input-18-75bec30a55f8>:14: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  df_tmp['Response Ratio'] = df_tmp['Area'].values / df_tmp['ISTD Response'].values\n"
     ]
    }
   ],
   "source": [
    "### Read calibration data:\n",
    "### Replace all N/F with 0 before start ###\n",
    "# input_fnam = 'cal-curve_LCMS-data_runs/AA_quant_april_22.xlsx'\n",
    "# input_fnam = 'cal-curve_LCMS-data_runs/AA_quant_aug21.xlsx'\n",
    "input_fnam = 'cal-curve_LCMS-data_runs/AA_quant_oct20.xlsx'\n",
    "esheet_dict_cal = pd.read_excel(input_fnam, sheet_name=None)\n",
    "metab_dict_cal = dict()\n",
    "metab_names_cal = list()\n",
    "for k in esheet_dict_cal.keys():\n",
    "    if 'U-13C' not in k:\n",
    "        metab_names_cal.append(k)\n",
    "        # Remove non calibration standards and zero peaks:\n",
    "        df_tmp = copy.deepcopy(esheet_dict_cal[k])\n",
    "        df_tmp['Response Ratio'] = df_tmp['Area'].values / df_tmp['ISTD Response'].values\n",
    "        mask_cal = df_tmp['Theoretical Amt'].values > 0\n",
    "        metab_dict_cal[k] = df_tmp.loc[mask_cal]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3e63e40cfe03>:67: RuntimeWarning: overflow encountered in power\n",
      "  return(alpha + beta*x**gamma)\n",
      "/Users/krdav/anaconda3/lib/python3.8/site-packages/scipy/optimize/_numdiff.py:497: RuntimeWarning: invalid value encountered in subtract\n",
      "  df = fun(x) - f0\n",
      "<ipython-input-2-3e63e40cfe03>:67: RuntimeWarning: overflow encountered in multiply\n",
      "  return(alpha + beta*x**gamma)\n",
      "<ipython-input-2-3e63e40cfe03>:256: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  beta_lower = (y_upper - y_lower) / (ub - lb)\n",
      "<ipython-input-2-3e63e40cfe03>:259: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha_lower = y_upper - beta_lower*ub\n",
      "<ipython-input-2-3e63e40cfe03>:67: RuntimeWarning: invalid value encountered in multiply\n",
      "  return(alpha + beta*x**gamma)\n"
     ]
    }
   ],
   "source": [
    "### Fit calibration curve ###\n",
    "piece_wise_fit = dict()\n",
    "for metab in metab_names_cal:\n",
    "    amt_uM = metab_dict_cal[metab]['Theoretical Amt'].values\n",
    "    rsp_ratio = metab_dict_cal[metab]['Response Ratio'].values\n",
    "    df = metab_dict_cal[metab]\n",
    "    # Extract the fitting range:\n",
    "    amt_uM_range = sorted(np.unique(amt_uM), reverse=True)\n",
    "    rsp_ratio_range = [np.average(rsp_ratio[(amt_uM == r)]) for r in amt_uM_range]\n",
    "    amt_uM_range.append(0)\n",
    "    amt_uM_range.insert(0, float('inf'))\n",
    "    rsp_ratio_range.append(0)\n",
    "    rsp_ratio_range.insert(0, float('inf'))\n",
    "    # Fit the data:\n",
    "    piece_wise_fit[metab] = make_piece_wise_fit(amt_uM, rsp_ratio, amt_uM_range, rsp_ratio_range, df, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-5017cbac4806>:24: RuntimeWarning: divide by zero encountered in log10\n",
      "  x = np.logspace(np.log10(lb), np.log10(ub), 1000)\n",
      "/Users/krdav/anaconda3/lib/python3.8/site-packages/numpy/core/function_base.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  delta = stop - start\n",
      "<ipython-input-2-3e63e40cfe03>:260: RuntimeWarning: invalid value encountered in multiply\n",
      "  piece_wise_fit[key_between_intra_low] = lambda x: alpha_lower + beta_lower*x\n"
     ]
    }
   ],
   "source": [
    "### Plot measured values on calibration curve ###\n",
    "# output_ext = 'april_22'\n",
    "# output_ext = 'aug_21'\n",
    "output_ext = 'oct_20'\n",
    "fnam_out = 'calibration_curves_{}.pdf'.format(output_ext)\n",
    "save_pdf = True\n",
    "if save_pdf:\n",
    "    pdf = matplotlib.backends.backend_pdf.PdfPages(fnam_out)\n",
    "    for metab in metab_names_cal:\n",
    "        fig = plot_cal_piece_wise_fit(metab, metab_dict_cal[metab], piece_wise_fit[metab], save=save_pdf)\n",
    "        pdf.savefig(fig)\n",
    "        plt.close(fig)\n",
    "    pdf.close()\n",
    "else:\n",
    "    for metab in metab_names_cal:\n",
    "        plot_cal_piece_wise_fit(metab, metab_dict_cal[metab], piece_wise_fit[metab], save=save_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle all the relevant compounds:\n",
    "dict_pickle_fnam = 'AA-quant_{}.pickle'.format(output_ext)\n",
    "all_comp = list(piece_wise_fit.keys())\n",
    "# not_quant = ['Histidine pos', 'Cystine pos']\n",
    "not_quant = ['Histidine pos', 'Cystine pos', 'Glycine neg']\n",
    "for metab in not_quant:\n",
    "    if metab in piece_wise_fit:\n",
    "        del piece_wise_fit[metab]\n",
    "\n",
    "with open(dict_pickle_fnam, 'wb') as handle:\n",
    "    pickle.dump(piece_wise_fit, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
